{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3990b1ea-42c5-4fe4-9fd7-e709b9254ca1",
   "metadata": {
    "id": "3990b1ea-42c5-4fe4-9fd7-e709b9254ca1"
   },
   "source": [
    "# Pendulum RL Demo: Hyperparameter Optimization with Meta Ax\n",
    "\n",
    "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/reinforcement-learning-demos/blob/main/rl-demo-pendulum-ax-hpo.ipynb)\n",
    "\n",
    "This example demonstrates Bayesian Optimization to find good hyperparameters using [Meta Ax](https://ax.dev/). Trial results are saved to [Weights & Biases](https://wandb.ai/site) so you can remotely watch training in real-time and later review the hyperparameters for each trial. We use the basic [gymnasium pendulum environment](https://gymnasium.farama.org/environments/classic_control/pendulum/) and [PPO from stable-baselines3](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html) as our reinforcement learning agent.\n",
    "\n",
    "Start with [this pendulum demo](https://github.com/ShawnHymel/reinforcement-learning-demos/blob/main/rl-demo-pendulum.ipynb) to see how RL training works. In that example, we pull hyperparameters from a known-good source ([rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo)). But what happens when you don't have good hyperparameters to start with? RL can be tricky and vary wildly depending on what hyperparameters you use. So, hyperparameter tuning is very important. We use a combination of Ax (for Bayesian Optimization) and W&B (for experiment logging) to show how autotuning can be done (especially when model training is computationally expensive and time-consuming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b03c626-ed19-4a89-8206-bf06e4e56f93",
   "metadata": {
    "id": "1b03c626-ed19-4a89-8206-bf06e4e56f93"
   },
   "outputs": [],
   "source": [
    "# !python -m pip install gymnasium==0.28.1\n",
    "# !python -m pip install stable-baselines3[extra]==2.1.0\n",
    "# !python -m pip install ax-platform==0.3.4\n",
    "# !python -m pip install wandb==0.15.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66e8d1a-e4c2-45ef-a123-698896b1e9cc",
   "metadata": {
    "id": "f66e8d1a-e4c2-45ef-a123-698896b1e9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0\n",
      "gymnasium version: 0.28.1\n",
      "sb3 version: 2.1.0\n",
      "cv2 version: 4.7.0.68\n",
      "ax version: 0.3.4\n"
     ]
    }
   ],
   "source": [
    "# Check versions\n",
    "import importlib.metadata\n",
    "\n",
    "print(f\"torch version: {importlib.metadata.version('torch')}\")\n",
    "print(f\"gymnasium version: {importlib.metadata.version('gymnasium')}\")\n",
    "print(f\"sb3 version: {importlib.metadata.version('stable-baselines3')}\")\n",
    "print(f\"cv2 version: {importlib.metadata.version('opencv-python')}\")\n",
    "print(f\"ax version: {importlib.metadata.version('ax-platform')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fb1f95-ee81-4d47-9761-ed9e1bacc30a",
   "metadata": {
    "id": "e9fb1f95-ee81-4d47-9761-ed9e1bacc30a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import cv2\n",
    "import wandb\n",
    "\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import KVWriter, Logger\n",
    "\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3661e6-9a0c-430a-802d-4bc95c81932a",
   "metadata": {
    "id": "3c3661e6-9a0c-430a-802d-4bc95c81932a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshawnhymel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to Weights & Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075a089e-2835-46ca-990d-127add0d0cad",
   "metadata": {
    "id": "075a089e-2835-46ca-990d-127add0d0cad"
   },
   "outputs": [],
   "source": [
    "# Make wandb be quiet\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "logger = logging.getLogger(\"wandb\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08abcee-0c9c-4595-9eca-240931aff795",
   "metadata": {
    "id": "e08abcee-0c9c-4595-9eca-240931aff795"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b535fb29-726a-4189-a2f7-2f888b9f4dc3",
   "metadata": {
    "id": "b535fb29-726a-4189-a2f7-2f888b9f4dc3"
   },
   "outputs": [],
   "source": [
    "def set_random_seeds(seed: int, using_cuda: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Seed the different random generators.\n",
    "    https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/utils.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for Python random, NumPy, and Torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "\n",
    "    # Set deterministic operations for CUDA\n",
    "    if using_cuda:\n",
    "        th.backends.cudnn.deterministic = True\n",
    "        th.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794a1eb-7ebf-4cfc-8e42-bed2957e70cb",
   "metadata": {
    "id": "8794a1eb-7ebf-4cfc-8e42-bed2957e70cb"
   },
   "source": [
    "## Set up environment\n",
    "\n",
    "Create pendulum environment from gymnasium. Test the environment using a dummy agent that simply predicts random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ccafdc-aab0-40d0-a7f4-17c0bf96befa",
   "metadata": {
    "id": "f9ccafdc-aab0-40d0-a7f4-17c0bf96befa"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "# https://gymnasium.farama.org/api/env/\n",
    "env = gym.make('Pendulum-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "888beb0f-6ed3-420b-ad91-3caefd70bf6e",
   "metadata": {
    "id": "888beb0f-6ed3-420b-ad91-3caefd70bf6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99875486 0.04988773 0.99376863]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Reset the pendulum environment\n",
    "# https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
    "obs, info = env.reset()\n",
    "print(obs)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac722bc-1386-42f5-b919-a0371e1f1578",
   "metadata": {
    "id": "fac722bc-1386-42f5-b919-a0371e1f1578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef4f9e7100>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGiCAYAAABd6zmYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhM0lEQVR4nO3df2zV9aH/8dc5Pe0ppZxTCvQcGlohkSs2/JgCwpnJ3B0d1XVOJ0ucIa5zXI2sEJCFTDbFaJaU4Pc7pxviEjPx5k5Z2B06GeiaomXOCljpLAU7l6HthNMi2HNaoKc/zvv7h+F8PVJdW07PeZ+e5yM5iXw+73P6Pm9pn3zO+fRzHMYYIwAALORM9QQAAPg8RAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYK2URWrbtm2aOXOmcnNztWTJEh06dChVUwEAWColkfrd736nDRs26KGHHtLbb7+tBQsWqKKiQp2dnamYDgDAUo5UXGB2yZIlWrx4sX71q19JkqLRqEpKSrR27Vrdf//9yZ4OAMBSrmR/wb6+PjU2NmrTpk2xbU6nU+Xl5WpoaBjyPpFIRJFIJPbnaDSqs2fPasqUKXI4HGM+ZwBAYhlj1N3dreLiYjmdn/+iXtIj9dFHH2lwcFA+ny9uu8/n07vvvjvkfWpqavTwww8nY3oAgCRqb2/XjBkzPnd/0iM1Gps2bdKGDRtifw6FQiotLVV7e7s8Hk8KZwYAGI1wOKySkhJNmjTpC8clPVJTp05VVlaWOjo64rZ3dHTI7/cPeR+32y23233Jdo/HQ6QAII39u7dskn52X05OjhYuXKi6urrYtmg0qrq6OgUCgWRPBwBgsZS83LdhwwZVVVVp0aJFuu666/SLX/xC586d01133ZWK6QAALJWSSN1+++06ffq0Nm/erGAwqC996Ut6+eWXLzmZAgCQ2VLye1KXKxwOy+v1KhQK8Z4UAKSh4f4c59p9AABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKw14kgdOHBAN998s4qLi+VwOPTCCy/E7TfGaPPmzZo+fbomTJig8vJyvffee3Fjzp49q5UrV8rj8aigoECrVq1ST0/PZT0RAMD4M+JInTt3TgsWLNC2bduG3L9161Y98cQTeuqpp3Tw4EFNnDhRFRUV6u3tjY1ZuXKlWlpaVFtbqz179ujAgQO65557Rv8sAADjk7kMkszu3btjf45Go8bv95tHH300tq2rq8u43W7z/PPPG2OMOXbsmJFkDh8+HBuzb98+43A4zIcffjisrxsKhYwkEwqFLmf6AIAUGe7P8YS+J3XixAkFg0GVl5fHtnm9Xi1ZskQNDQ2SpIaGBhUUFGjRokWxMeXl5XI6nTp48OCQjxuJRBQOh+NuAIDxL6GRCgaDkiSfzxe33efzxfYFg0EVFRXF7Xe5XCosLIyN+ayamhp5vd7YraSkJJHTBgBYKi3O7tu0aZNCoVDs1t7enuopAQCSIKGR8vv9kqSOjo647R0dHbF9fr9fnZ2dcfsHBgZ09uzZ2JjPcrvd8ng8cTcAwPiX0EjNmjVLfr9fdXV1sW3hcFgHDx5UIBCQJAUCAXV1damxsTE2Zv/+/YpGo1qyZEkipwMASHOukd6hp6dH//jHP2J/PnHihJqamlRYWKjS0lKtX79eP/vZzzR79mzNmjVLDz74oIqLi3XrrbdKkq6++mrdeOONuvvuu/XUU0+pv79fa9as0Xe/+10VFxcn7IkBAMaBkZ42+OqrrxpJl9yqqqqMMZ+chv7ggw8an89n3G63WbZsmWltbY17jDNnzpg77rjD5OfnG4/HY+666y7T3d2d8FMXAQB2Gu7PcYcxxqSwkaMSDofl9XoVCoV4fwoA0tBwf46nxdl9AIDMRKQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYa8QVmASTG4PnzOv/Pf+rCBx9ooLtbcjiUPXmy8q64QhNmzZIzJyfVUwRSjkgBSWYGB9Vz/LiCv/+9LrS1aSAclunvlyQ53W65PB7lzZ6t4u9+V7klJXI4ecEDmYtIAUk0eO6cTv/5zzq1c6eiFy5csj/a26u+3l71dXbq3LvvqnjlShV+5SscVSFj8U80IEmi/f3qfPllBXftGjJQn9V/5oxO/s//6OO//lVp+GEFQEIQKSBJeo4eVXDXLg329Az7Pv1nz+rD//5v9X7wwRjODLAXkQKSYPDCBX2wfbui58+P+L79Z87oX888o2gkMgYzA+xGpIAkOPvaaxr4+ONR3//8iRMKv/NOAmcEpAciBSTB+RMnLutIaKCrS33BYAJnBKQHIgWkCRONcgIFMg6RAsbYuffeU3cCXqqLRiJSNJqAGQHpg0gBY6zv9GlFTp687MeJRiIyRAoZhkgBaYIjKWQiIgWkCY6kkImIFJAmor29RAoZh0gBaYKX+5CJiBSQJnqOHx/RJZWA8YBIAWPMmZMjZ27uZT/OQCik6MBAAmYEpA8iBYwxd3GxJsycmeppAGmJSAFjzOFyyZGdneppAGmJSAFjzJmdzYcWAqNEpIAx5nC55ORIChgVIgWMMV7uA0aPSAFjzOFyJe7lPq6EjgxDpIAx5nC55HC5EvJYgxcuJORxgHRBpIAx5nA4JIcjIY81OIqPnwfSGZEC0ghHUsg0RApII1EihQxDpIA0wst9yDRECkgjRAqZhkgBaST89tupngKQVEQKSIKsCRMk5+V/u0VOnUrAbID0QaSAJPAsXChXfn6qpwGkHSIFJIHT7U7IkRSQafiuAZIgKzf3k1/qBTAiRApIAo6kgNHhuwZIAqfbLQeRAkaM7xogCZwJOrtPksRV0JFBiBSQBM6cnIS8J2WM0WBvbwJmBKQHIgUkgcPpTMyV0I1RlEghgxApIJ1Eo1xkFhmFSAHpxBgNRiKpngWQNEQKSCPGGI6kkFGIFJBOeE8KGYZIAWkk2t+vnuPHUz0NIGmIFJAkTrf78h9kcJAroSOjECkgSaYuX57qKQBph0gBSeKcMCHVUwDSDpECkiQrLy/VUwDSDpECkoRIASNHpIAk4eU+YOSIFJAkrkQdSRkjw5XQkSGIFJAkztzchDyOGRiQ6e9PyGMBtiNSQLIk6OPjzcCAzMBAQh4LsN2IIlVTU6PFixdr0qRJKioq0q233qrW1ta4Mb29vaqurtaUKVOUn5+vFStWqKOjI25MW1ubKisrlZeXp6KiIm3cuFEDfNMBwxIdGFC0ry/V0wCSYkSRqq+vV3V1td58803V1taqv79fy5cv17lz52Jj7rvvPr300kvatWuX6uvrdfLkSd12222x/YODg6qsrFRfX5/eeOMNPfvss9qxY4c2b96cuGcFjGMcSSGTOMxlvAN7+vRpFRUVqb6+Xl/5ylcUCoU0bdo0Pffcc/rOd74jSXr33Xd19dVXq6GhQUuXLtW+ffv0zW9+UydPnpTP55MkPfXUU/rxj3+s06dPKycn599+3XA4LK/Xq1AoJI/HM9rpA0nVd+aMmu+667IfZ+JVV2nmhg3KnT49AbMCUmO4P8cv6z2pUCgkSSosLJQkNTY2qr+/X+Xl5bExc+bMUWlpqRoaGiRJDQ0NmjdvXixQklRRUaFwOKyWlpYhv04kElE4HI67AZkqyokTyCCjjlQ0GtX69et1/fXXa+7cuZKkYDConJwcFRQUxI31+XwKBoOxMZ8O1MX9F/cNpaamRl6vN3YrKSkZ7bSBtNf/0Ufq+8z7vMB4NepIVVdX6+jRo9q5c2ci5zOkTZs2KRQKxW7t7e1j/jWBRHPm5mrS/PmX/TgDoZD6P/44ATMC7OcazZ3WrFmjPXv26MCBA5oxY0Zsu9/vV19fn7q6uuKOpjo6OuT3+2NjDh06FPd4F8/+uzjms9xut9yJ+JgDIIUcWVnKnjIl1dMA0sqIjqSMMVqzZo12796t/fv3a9asWXH7Fy5cqOzsbNXV1cW2tba2qq2tTYFAQJIUCATU3Nyszs7O2Jja2lp5PB6VlZVdznMBrOZwOBLzmVJABhnRkVR1dbWee+45vfjii5o0aVLsPSSv16sJEybI6/Vq1apV2rBhgwoLC+XxeLR27VoFAgEtXbpUkrR8+XKVlZXpzjvv1NatWxUMBvXAAw+ourqaoyWMbw5Hwq46AWSKEUVq+/btkqSvfvWrcdufeeYZff/735ckPfbYY3I6nVqxYoUikYgqKir05JNPxsZmZWVpz549Wr16tQKBgCZOnKiqqio98sgjl/dMANs5ncriIrPAiIwoUsP5larc3Fxt27ZN27Zt+9wxV1xxhfbu3TuSLw2kPQdHUsCIce0+IFkSGCnDldCRIYgUkCwOh5zDuKLKcET7+iQihQxApIAkcTgcciToSujR3l4ihYxApIA0FO3tlYlGUz0NYMwRKSANRSMRiUghAxApIA1Fe3s5cQIZgUgBaWiwt5cjKWQEIgWkoQvvv8+n8yIjECkgidzTp8udgA8r7G1rI1LICEQKSCLXpEnKmjQp1dMA0gaRApLIkZ0tp2tUn5ADZCQiBSSRw+WSIzs71dMA0gaRApLImZ1NpIARIFJAEvFyHzAyRApIooS+3Mcv8yIDECkgiRwulxwJOpLiqhPIBEQKSKJEXQVdkgYvXEjYYwG2IlJAmho8fz7VUwDGHJEC0hRHUsgERApIU1GOpJABiBSQpjiSQiYgUkCaOv+Pf6R6CsCYI1JAkk2cM0eOnJzLfpyelpYEzAawG5ECkiy3uJirTgDDxHcKkGTO3FzJ+fn/Pvzw3DkdOXtW3f39mpabq8C0aZrI9f6QoYgUkGTO3FxpiF/qNcboRE+PHjpyRO/39Kh3cFCe7GzNnTxZ/2fxYmV/QdiA8Yq/9UCSZeXmDnnliX/29Ojuv/5Vx0MhXRgclJEU6u/XXzs7te7gQZ3p7U3+ZIEUI1JAkn3ey32/aGlRqL9/yPsc+ugj1Z48OdZTA6xDpIAkc7rdQ77cB+BSRApIMqfbrYlXXpnqaQBpgUgBSeZwODTjv/7rku2VJSXK/pwjrJn5+ZpfWDjWUwOsQ6SAFMj2elX4n/8Zt62iuFgPXXONcrOyYt+YWQ6Hprjd+r+LF6usoCBuvG/FiuRMFkghTkEHUsA5YYImBwIKvfWWBru7JX1yhFVRXKwZeXna869/6Uxvr2bm5+v2WbM0xe2Ou797+nRNDgQS+vlUgI2IFJACDodDnmuu0bSbblLH//6vzOBgbPvcyZM1d/Lkz72va/JkFd95p1weT7KmC6QML/cBKeJ0u+X79rdV+LWvDfsj5bPy8zX99ttVcN11cmRljfEMgdTjSApIoay8PM34wQ+UXVios6++qr7OziHHObKylFtS8knUvvpVXuZDxiBSQAo5HA65Jk7U9O98R5758/XxG2+op6VFkWBQ0UhEWfn5yp0xQ95Fi+RdtEgTSksJFDIKkQIs4HS7lT93rib+x39o8MIFmYEBmWhUjqwsObOz5czL48rpyEj8rQcs4XA45HC7P7kiBQBJnDgBALAYkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgrRFFavv27Zo/f748Ho88Ho8CgYD27dsX29/b26vq6mpNmTJF+fn5WrFihTo6OuIeo62tTZWVlcrLy1NRUZE2btyogYGBxDwbAMC4MqJIzZgxQ1u2bFFjY6Peeustfe1rX9Mtt9yilpYWSdJ9992nl156Sbt27VJ9fb1Onjyp2267LXb/wcFBVVZWqq+vT2+88YaeffZZ7dixQ5s3b07sswIAjA/mMk2ePNk8/fTTpqury2RnZ5tdu3bF9h0/ftxIMg0NDcYYY/bu3WucTqcJBoOxMdu3bzcej8dEIpFhf81QKGQkmVAodLnTBwCkwHB/jo/6PanBwUHt3LlT586dUyAQUGNjo/r7+1VeXh4bM2fOHJWWlqqhoUGS1NDQoHnz5snn88XGVFRUKBwOx47GhhKJRBQOh+NuAIDxb8SRam5uVn5+vtxut+69917t3r1bZWVlCgaDysnJUUFBQdx4n8+nYDAoSQoGg3GBurj/4r7PU1NTI6/XG7uVlJSMdNoAgDQ04khdddVVampq0sGDB7V69WpVVVXp2LFjYzG3mE2bNikUCsVu7e3tY/r1AAB2cI30Djk5ObryyislSQsXLtThw4f1+OOP6/bbb1dfX5+6urrijqY6Ojrk9/slSX6/X4cOHYp7vItn/10cMxS32y232z3SqQIA0txl/55UNBpVJBLRwoULlZ2drbq6uti+1tZWtbW1KRAISJICgYCam5vV2dkZG1NbWyuPx6OysrLLnQoAYJwZ0ZHUpk2bdNNNN6m0tFTd3d167rnn9Nprr+mVV16R1+vVqlWrtGHDBhUWFsrj8Wjt2rUKBAJaunSpJGn58uUqKyvTnXfeqa1btyoYDOqBBx5QdXU1R0oAgEuMKFKdnZ363ve+p1OnTsnr9Wr+/Pl65ZVX9PWvf12S9Nhjj8npdGrFihWKRCKqqKjQk08+Gbt/VlaW9uzZo9WrVysQCGjixImqqqrSI488kthnBQAYFxzGGJPqSYxUOByW1+tVKBSSx+NJ9XQAACM03J/jXLsPAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLUuK1JbtmyRw+HQ+vXrY9t6e3tVXV2tKVOmKD8/XytWrFBHR0fc/dra2lRZWam8vDwVFRVp48aNGhgYuJypAADGoVFH6vDhw/r1r3+t+fPnx22/77779NJLL2nXrl2qr6/XyZMnddttt8X2Dw4OqrKyUn19fXrjjTf07LPPaseOHdq8efPonwUAYHwyo9Dd3W1mz55tamtrzQ033GDWrVtnjDGmq6vLZGdnm127dsXGHj9+3EgyDQ0Nxhhj9u7da5xOpwkGg7Ex27dvNx6Px0QikWF9/VAoZCSZUCg0mukDAFJsuD/HR3UkVV1drcrKSpWXl8dtb2xsVH9/f9z2OXPmqLS0VA0NDZKkhoYGzZs3Tz6fLzamoqJC4XBYLS0tQ369SCSicDgcdwMAjH+ukd5h586devvtt3X48OFL9gWDQeXk5KigoCBuu8/nUzAYjI35dKAu7r+4byg1NTV6+OGHRzpVAECaG9GRVHt7u9atW6ff/va3ys3NHas5XWLTpk0KhUKxW3t7e9K+NgAgdUYUqcbGRnV2duraa6+Vy+WSy+VSfX29nnjiCblcLvl8PvX19amrqyvufh0dHfL7/ZIkv99/ydl+F/98ccxnud1ueTyeuBsAYPwbUaSWLVum5uZmNTU1xW6LFi3SypUrY/+dnZ2turq62H1aW1vV1tamQCAgSQoEAmpublZnZ2dsTG1trTwej8rKyhL0tAAA48GI3pOaNGmS5s6dG7dt4sSJmjJlSmz7qlWrtGHDBhUWFsrj8Wjt2rUKBAJaunSpJGn58uUqKyvTnXfeqa1btyoYDOqBBx5QdXW13G53gp4WAGA8GPGJE//OY489JqfTqRUrVigSiaiiokJPPvlkbH9WVpb27Nmj1atXKxAIaOLEiaqqqtIjjzyS6KkAANKcwxhjUj2JkQqHw/J6vQqFQrw/BQBpaLg/x7l2HwDAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWq5UT2A0jDGSpHA4nOKZAABG4+LP74s/zz9PWkbqzJkzkqSSkpIUzwQAcDm6u7vl9Xo/d39aRqqwsFCS1NbW9oVPLtOFw2GVlJSovb1dHo8n1dOxFus0PKzT8LBOw2OMUXd3t4qLi79wXFpGyun85K00r9fLX4Jh8Hg8rNMwsE7DwzoND+v07w3nIIMTJwAA1iJSAABrpWWk3G63HnroIbnd7lRPxWqs0/CwTsPDOg0P65RYDvPvzv8DACBF0vJICgCQGYgUAMBaRAoAYC0iBQCwVlpGatu2bZo5c6Zyc3O1ZMkSHTp0KNVTSqoDBw7o5ptvVnFxsRwOh1544YW4/cYYbd68WdOnT9eECRNUXl6u9957L27M2bNntXLlSnk8HhUUFGjVqlXq6elJ4rMYWzU1NVq8eLEmTZqkoqIi3XrrrWptbY0b09vbq+rqak2ZMkX5+flasWKFOjo64sa0tbWpsrJSeXl5Kioq0saNGzUwMJDMpzKmtm/frvnz58d+8TQQCGjfvn2x/azR0LZs2SKHw6H169fHtrFWY8SkmZ07d5qcnBzzm9/8xrS0tJi7777bFBQUmI6OjlRPLWn27t1rfvrTn5o//OEPRpLZvXt33P4tW7YYr9drXnjhBfO3v/3NfOtb3zKzZs0yFy5ciI258cYbzYIFC8ybb75p/vKXv5grr7zS3HHHHUl+JmOnoqLCPPPMM+bo0aOmqanJfOMb3zClpaWmp6cnNubee+81JSUlpq6uzrz11ltm6dKl5stf/nJs/8DAgJk7d64pLy83R44cMXv37jVTp041mzZtSsVTGhN//OMfzZ/+9Cfz97//3bS2tpqf/OQnJjs72xw9etQYwxoN5dChQ2bmzJlm/vz5Zt26dbHtrNXYSLtIXXfddaa6ujr258HBQVNcXGxqampSOKvU+WykotGo8fv95tFHH41t6+rqMm632zz//PPGGGOOHTtmJJnDhw/Hxuzbt884HA7z4YcfJm3uydTZ2Wkkmfr6emPMJ2uSnZ1tdu3aFRtz/PhxI8k0NDQYYz75x4DT6TTBYDA2Zvv27cbj8ZhIJJLcJ5BEkydPNk8//TRrNITu7m4ze/ZsU1tba2644YZYpFirsZNWL/f19fWpsbFR5eXlsW1Op1Pl5eVqaGhI4czsceLECQWDwbg18nq9WrJkSWyNGhoaVFBQoEWLFsXGlJeXy+l06uDBg0mfczKEQiFJ///ixI2Njerv749bpzlz5qi0tDRunebNmyefzxcbU1FRoXA4rJaWliTOPjkGBwe1c+dOnTt3ToFAgDUaQnV1tSorK+PWROLv01hKqwvMfvTRRxocHIz7nyxJPp9P7777bopmZZdgMChJQ67RxX3BYFBFRUVx+10ulwoLC2NjxpNoNKr169fr+uuv19y5cyV9sgY5OTkqKCiIG/vZdRpqHS/uGy+am5sVCATU29ur/Px87d69W2VlZWpqamKNPmXnzp16++23dfjw4Uv28fdp7KRVpIDRqK6u1tGjR/X666+neipWuuqqq9TU1KRQKKTf//73qqqqUn19faqnZZX29natW7dOtbW1ys3NTfV0Mkpavdw3depUZWVlXXLGTEdHh/x+f4pmZZeL6/BFa+T3+9XZ2Rm3f2BgQGfPnh1367hmzRrt2bNHr776qmbMmBHb7vf71dfXp66urrjxn12nodbx4r7xIicnR1deeaUWLlyompoaLViwQI8//jhr9CmNjY3q7OzUtddeK5fLJZfLpfr6ej3xxBNyuVzy+Xys1RhJq0jl5ORo4cKFqquri22LRqOqq6tTIBBI4czsMWvWLPn9/rg1CofDOnjwYGyNAoGAurq61NjYGBuzf/9+RaNRLVmyJOlzHgvGGK1Zs0a7d+/W/v37NWvWrLj9CxcuVHZ2dtw6tba2qq2tLW6dmpub44JeW1srj8ejsrKy5DyRFIhGo4pEIqzRpyxbtkzNzc1qamqK3RYtWqSVK1fG/pu1GiOpPnNjpHbu3GncbrfZsWOHOXbsmLnnnntMQUFB3Bkz4113d7c5cuSIOXLkiJFkfv7zn5sjR46YDz74wBjzySnoBQUF5sUXXzTvvPOOueWWW4Y8Bf2aa64xBw8eNK+//rqZPXv2uDoFffXq1cbr9ZrXXnvNnDp1KnY7f/58bMy9995rSktLzf79+81bb71lAoGACQQCsf0XTxlevny5aWpqMi+//LKZNm3auDpl+P777zf19fXmxIkT5p133jH333+/cTgc5s9//rMxhjX6Ip8+u88Y1mqspF2kjDHml7/8pSktLTU5OTnmuuuuM2+++Waqp5RUr776qpF0ya2qqsoY88lp6A8++KDx+XzG7XabZcuWmdbW1rjHOHPmjLnjjjtMfn6+8Xg85q677jLd3d0peDZjY6j1kWSeeeaZ2JgLFy6YH/7wh2by5MkmLy/PfPvb3zanTp2Ke5z333/f3HTTTWbChAlm6tSp5kc/+pHp7+9P8rMZOz/4wQ/MFVdcYXJycsy0adPMsmXLYoEyhjX6Ip+NFGs1NvioDgCAtdLqPSkAQGYhUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFr/D5JcBo6Vb7HcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the environment (render is not the observation!) and get width and height\n",
    "frame = env.render()\n",
    "width = frame.shape[1]\n",
    "height = frame.shape[0]\n",
    "\n",
    "# Show frame\n",
    "print(frame.shape)\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283d7147-c506-4779-8dd4-0d821d6495d0",
   "metadata": {
    "id": "283d7147-c506-4779-8dd4-0d821d6495d0"
   },
   "outputs": [],
   "source": [
    "# Function that tests the model in the given environment\n",
    "def test_agent(env, model, max_steps=0, video=None, msg=None):\n",
    "\n",
    "    # Reset environment\n",
    "    obs, info = env.reset()\n",
    "    ep_len = 0\n",
    "    ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "\n",
    "    # Run episode until complete\n",
    "    while True:\n",
    "\n",
    "        # Provide observation to policy to predict the next action\n",
    "        timestamp = time.time()\n",
    "        action, _ = model.predict(obs)\n",
    "\n",
    "        # Perform action, update total reward\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        avg_step_time += time.time() - timestamp\n",
    "        ep_rew += reward\n",
    "\n",
    "        # Record frame to video\n",
    "        if video:\n",
    "            frame = env.render()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            frame = cv2.putText(\n",
    "                frame,                    # Image\n",
    "                msg,                      # Text to add\n",
    "                (10, 25),                 # Origin of text in imagg\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, # Font\n",
    "                1,                        # Font scale\n",
    "                (0, 0, 0,),               # Color\n",
    "                2,                        # Thickness\n",
    "                cv2.LINE_AA               # Line type\n",
    "            )\n",
    "            video.write(frame)\n",
    "\n",
    "        # Increase step counter\n",
    "        ep_len += 1\n",
    "        if (max_steps > 0) and (ep_len >= max_steps):\n",
    "            break\n",
    "\n",
    "        # Check to see if episode has ended\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    # Calculate average step time\n",
    "    avg_step_time /= ep_len\n",
    "\n",
    "    return ep_len, ep_rew, avg_step_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646486ea-8ab6-4a18-86d3-ced7651e5d6f",
   "metadata": {
    "id": "646486ea-8ab6-4a18-86d3-ced7651e5d6f"
   },
   "outputs": [],
   "source": [
    "class DummyAgent():\n",
    "    \"\"\"\n",
    "    Agent that just predicts random actions\n",
    "    \"\"\"\n",
    "\n",
    "    # Save environment\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    # Always output random action regardless of observation\n",
    "    def predict(self, obs):\n",
    "        action = self.env.action_space.sample()\n",
    "        return action, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970770b4-9f48-41a9-8ec4-6ed6bb93cfb1",
   "metadata": {
    "id": "970770b4-9f48-41a9-8ec4-6ed6bb93cfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 | Length: 100, Reward: -492.18571178914056, Step time: 2.02e-01 ms\n",
      "Episode 1 | Length: 100, Reward: -378.5471863724411, Step time: 1.62e-01 ms\n",
      "Episode 2 | Length: 100, Reward: -499.8621798576484, Step time: 2.04e-01 ms\n",
      "Episode 3 | Length: 100, Reward: -483.6758040435373, Step time: 1.28e-01 ms\n",
      "Episode 4 | Length: 100, Reward: -515.4468645790975, Step time: 1.69e-01 ms\n"
     ]
    }
   ],
   "source": [
    "# Recorder settings\n",
    "FPS = 30\n",
    "FOURCC = cv2.VideoWriter.fourcc('m', 'p', '4', 'v')\n",
    "VIDEO_FILENAME = \"1-random.mp4\"\n",
    "\n",
    "# Create recorder\n",
    "video = cv2.VideoWriter(VIDEO_FILENAME, FOURCC, FPS, (width, height))\n",
    "\n",
    "# Try running a few episodes with the environment and random actions\n",
    "dummy_agent = DummyAgent(env)\n",
    "for ep in range(5):\n",
    "    ep_len, ep_rew, step_time = test_agent(env, dummy_agent, max_steps=100, video=video, msg=f\"Random, episode {ep}\")\n",
    "    print(f\"Episode {ep} | Length: {ep_len}, Reward: {ep_rew}, Step time: {(step_time * 1000):.2e} ms\")\n",
    "\n",
    "# Close the video writer\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86379700-764c-4a96-b3a3-d7554c95c8e5",
   "metadata": {
    "id": "86379700-764c-4a96-b3a3-d7554c95c8e5"
   },
   "source": [
    "## Testing and logging callbacks\n",
    "\n",
    "Construct custom callbacks for Stable-Baselines3 to test our agent and log metrics to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc684397-df3e-4061-b0aa-c3e3811346c1",
   "metadata": {
    "id": "dc684397-df3e-4061-b0aa-c3e3811346c1"
   },
   "outputs": [],
   "source": [
    "# Evaluate agent on a number of tests\n",
    "def evaluate_agent(env, model, steps_per_test, num_tests):\n",
    "\n",
    "    # Initialize metrics\n",
    "    avg_ep_len = 0\n",
    "    avg_ep_rew = 0\n",
    "    avg_step_time = 0.0\n",
    "\n",
    "    # Test the agent a number of times\n",
    "    for ep in range(num_tests):\n",
    "        ep_len, ep_rew, step_time = test_agent(env, model, max_steps=steps_per_test)\n",
    "        avg_ep_len += ep_len\n",
    "        avg_ep_rew += ep_rew\n",
    "        avg_step_time += step_time\n",
    "\n",
    "    # Compute metrics\n",
    "    avg_ep_len /= num_tests\n",
    "    avg_ep_rew /= num_tests\n",
    "    avg_step_time /= num_tests\n",
    "\n",
    "    return avg_ep_len, avg_ep_rew, avg_step_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7c3354-2049-465d-ba7f-8a17510cfc0b",
   "metadata": {
    "id": "4f7c3354-2049-465d-ba7f-8a17510cfc0b"
   },
   "outputs": [],
   "source": [
    "class EvalAndSaveCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Evaluate and save the model every ``check_freq`` steps\n",
    "\n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        check_freq,\n",
    "        save_dir,\n",
    "        model_name=\"model\",\n",
    "        replay_buffer_name=None,\n",
    "        steps_per_test=0,\n",
    "        num_tests=10,\n",
    "        step_offset=0,\n",
    "        verbose=1,\n",
    "    ):\n",
    "        super(EvalAndSaveCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = model_name\n",
    "        self.replay_buffer_name = replay_buffer_name\n",
    "        self.num_tests = num_tests\n",
    "        self.steps_per_test = steps_per_test\n",
    "        self.step_offset = step_offset\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Create directory for saving the models\n",
    "    def _init_callback(self):\n",
    "        if self.save_dir is not None:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    # Save and evaluate model at a set interval\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Set actual number of steps (including offset)\n",
    "            actual_steps = self.step_offset + self.n_calls\n",
    "\n",
    "            # Save model\n",
    "            model_path = os.path.join(self.save_dir, f\"{self.model_name}_{str(actual_steps)}\")\n",
    "            self.model.save(model_path)\n",
    "\n",
    "            # Save replay buffer\n",
    "            if self.replay_buffer_name != None:\n",
    "                replay_buffer_path = os.path.join(self.save_dir, f\"{self.replay_buffer_name}\")\n",
    "                self.model.save_replay_buffer(replay_buffer_path)\n",
    "\n",
    "            # Evaluate the agent\n",
    "            avg_ep_len, avg_ep_rew, avg_step_time = evaluate_agent(\n",
    "                env,\n",
    "                self.model,\n",
    "                self.steps_per_test,\n",
    "                self.num_tests\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"{str(actual_steps)} steps | average test length: {avg_ep_len}, average test reward: {avg_ep_rew}\")\n",
    "\n",
    "            # Log metrics to WandB\n",
    "            log_dict = {\n",
    "                'avg_ep_len': avg_ep_len,\n",
    "                'avg_ep_rew': avg_ep_rew,\n",
    "                'avg_step_time': avg_step_time,\n",
    "            }\n",
    "            wandb.log(log_dict, commit=True, step=actual_steps)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5293cee-c6d3-4b64-939c-6e53c00ea94a",
   "metadata": {
    "id": "e5293cee-c6d3-4b64-939c-6e53c00ea94a"
   },
   "outputs": [],
   "source": [
    "class WandBWriter(KVWriter):\n",
    "    \"\"\"\n",
    "    Log metrics to Weights & Biases when called by .learn()\n",
    "\n",
    "    More info: https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/common/logger.html#KVWriter\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize run\n",
    "    def __init__(self, run, verbose=1):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Write metrics to W&B project\n",
    "    def write(self,\n",
    "              key_values: Dict[str, Any],\n",
    "              key_excluded: Dict[str, Union[str, Tuple[str, ...]]],\n",
    "              step: int = 0) -> None:\n",
    "        log_dict = {}\n",
    "\n",
    "        # Go through each key/value pairs\n",
    "        for (key, value), (_, excluded) in zip(\n",
    "            sorted(key_values.items()), sorted(key_excluded.items())):\n",
    "\n",
    "            if self.verbose >= 2:\n",
    "                print(f\"step={step} | {key} : {value} ({type(value)})\")\n",
    "\n",
    "            # Skip excluded items\n",
    "            if excluded is not None and \"wandb\" in excluded:\n",
    "                continue\n",
    "\n",
    "            # Log integers and floats\n",
    "            if isinstance(value, np.ScalarType):\n",
    "                if not isinstance(value, str):\n",
    "                    wandb.log(data={key: value}, step=step)\n",
    "                    log_dict[key] = value\n",
    "\n",
    "        # Print to console\n",
    "        if self.verbose >= 1:\n",
    "            print(f\"Log for steps={step}\")\n",
    "            print(f\"--------------\")\n",
    "            for (key, value) in sorted(log_dict.items()):\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print()\n",
    "\n",
    "    # Close the W&B run\n",
    "    def close(self) -> None:\n",
    "        self.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f898db-18cc-4ea2-84e0-7435a6ba90bc",
   "metadata": {
    "id": "67f898db-18cc-4ea2-84e0-7435a6ba90bc"
   },
   "source": [
    "## Define train and test function for a single trial\n",
    "\n",
    "A single \"trial\" is fully training and then testing the agent using one set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b8c34f-bc3b-40a9-8a50-ae9f469e3dde",
   "metadata": {
    "id": "25b8c34f-bc3b-40a9-8a50-ae9f469e3dde"
   },
   "outputs": [],
   "source": [
    "def do_trial(settings, hparams):\n",
    "    \"\"\"\n",
    "    Training loop used to evaluate a set of hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seed\n",
    "    set_random_seeds(settings['seed'], using_cuda=th.cuda.is_available())\n",
    "\n",
    "    # Create new W&B run\n",
    "    config = {}\n",
    "    dt = datetime.datetime.now(datetime.timezone.utc)\n",
    "    dt = dt.replace(microsecond=0, tzinfo=None)\n",
    "    run = wandb.init(\n",
    "        project=settings['wandb_project'],\n",
    "        name=str(dt),\n",
    "        config=config,\n",
    "        settings=wandb.Settings(silent=(not settings['verbose_wandb']))\n",
    "    )\n",
    "\n",
    "    # Print run info\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"WandB run ID: {run.id}\")\n",
    "        print(f\"WandB run name: {run.name}\")\n",
    "\n",
    "    # Log hyperparameters to W&B\n",
    "    wandb.config.update(hparams)\n",
    "\n",
    "    # Set custom logger with our custom writer\n",
    "    wandb_writer = WandBWriter(run, verbose=settings['verbose_log'])\n",
    "    loggers = Logger(\n",
    "        folder=None,\n",
    "        output_formats=[wandb_writer]\n",
    "    )\n",
    "\n",
    "    # Calculate derived hyperparameters\n",
    "    n_steps = 2 ** hparams['steps_per_update_pow2']\n",
    "    minibatch_size = (hparams['n_envs'] * n_steps) // (2 ** hparams['batch_size_div_pow2'])\n",
    "    layer_1 = 2 ** hparams['layer_1_pow2']\n",
    "    layer_2 = 2 ** hparams['layer_2_pow2']\n",
    "\n",
    "\n",
    "    # Set completed steps to checkpoint number (in filename) or 0 to start over\n",
    "    # TODO: how to resume if trial is paused?\n",
    "    completed_steps = 0\n",
    "\n",
    "    # Load model or create new model\n",
    "    # PPO docs: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "    # Policy networks: https://stable-baselines.readthedocs.io/en/master/modules/policies.html\n",
    "    if completed_steps != 0:\n",
    "        model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(completed_steps)}.zip\")\n",
    "        model = sb3.PPO.load(model_path, env)\n",
    "        steps_to_complete = settings['total_steps'] - completed_steps\n",
    "    else:\n",
    "        model = sb3.PPO(\n",
    "            'MlpPolicy',\n",
    "            env,\n",
    "            learning_rate=hparams['learning_rate'], # Learning rate of neural network (default: 0.0003)\n",
    "            n_steps=n_steps,                        # Number of steps per update (default: 2048)\n",
    "            batch_size=minibatch_size,              # Minibatch size for NN update (default: 64)\n",
    "            gamma=hparams['gamma'],                 # Discount factor (default: 0.99)\n",
    "            ent_coef=hparams['entropy_coef'],       # Entropy, how much to explore (default: 0.0)\n",
    "            use_sde=hparams['use_sde'],             # Use generalized State Dependent Exploration (default: False)\n",
    "            sde_sample_freq=hparams['sde_freq'],    # Number of steps before sampling new noise matrix (default -1)\n",
    "            policy_kwargs={'net_arch': [layer_1, layer_2]}, # (default: [64, 64])\n",
    "            verbose=settings['verbose_train']       # Print training metrics (default: 0)\n",
    "        )\n",
    "        steps_to_complete = settings['total_steps']\n",
    "\n",
    "    # Set up checkpoint callback\n",
    "    checkpoint_callback = EvalAndSaveCallback(\n",
    "        check_freq=settings['checkpoint_freq'],\n",
    "        save_dir=settings['save_dir'],\n",
    "        model_name=settings['model_name'],\n",
    "        replay_buffer_name=settings['replay_buffer_name'],\n",
    "        steps_per_test=settings['steps_per_test'],\n",
    "        num_tests=settings['tests_per_check'],\n",
    "        step_offset=(settings['total_steps'] - steps_to_complete),\n",
    "        verbose=settings['verbose_test'],\n",
    "    )\n",
    "\n",
    "    # Choo choo train\n",
    "    model.learn(total_timesteps=steps_to_complete,\n",
    "                callback=[checkpoint_callback])\n",
    "\n",
    "    # Get dataframe of run metrics\n",
    "    history = wandb.Api().run(f\"{run.project}/{run.id}\").history()\n",
    "\n",
    "    # Get index of evaluation with maximum reward\n",
    "    max_idx = np.argmax(history.loc[:, 'avg_ep_rew'].values)\n",
    "\n",
    "    # Find number of steps required to produce that maximum reward\n",
    "    max_rew_steps = history['_step'][max_idx]\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"Steps with max reward: {max_rew_steps}\")\n",
    "\n",
    "    # Load model with maximum reward from previous run\n",
    "    model_path = os.path.join(settings['save_dir'], f\"{settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "    model = sb3.PPO.load(model_path, env)\n",
    "\n",
    "    # Evaluate the agent\n",
    "    avg_ep_len, avg_ep_rew, avg_step_time = evaluate_agent(\n",
    "        env,\n",
    "        model,\n",
    "        settings['steps_per_test'],\n",
    "        settings['tests_per_check'],\n",
    "    )\n",
    "\n",
    "    # Log final evaluation metrics to WandB run\n",
    "    wandb.run.summary['Average test episode length'] = avg_ep_len\n",
    "    wandb.run.summary['Average test episode reward'] = avg_ep_rew\n",
    "    wandb.run.summary['Average test step time'] = avg_step_time\n",
    "\n",
    "    # Print final run metrics\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(\"---\")\n",
    "        print(f\"Best model: {settings['model_name']}_{str(max_rew_steps)}.zip\")\n",
    "        print(f\"Average episode length: {avg_ep_len}\")\n",
    "        print(f\"Average episode reward: {avg_ep_rew}\")\n",
    "        print(f\"Average step time: {avg_step_time}\")\n",
    "\n",
    "    # Close W&B run\n",
    "    run.finish()\n",
    "\n",
    "    return avg_ep_rew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30c27a-7d64-4af2-a2b8-9d142c418554",
   "metadata": {
    "id": "ce30c27a-7d64-4af2-a2b8-9d142c418554"
   },
   "source": [
    "## Perform trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87c458c-6d9e-4b4d-af9a-e8f4a8899b27",
   "metadata": {
    "id": "a87c458c-6d9e-4b4d-af9a-e8f4a8899b27"
   },
   "outputs": [],
   "source": [
    "# Project settings that do not change\n",
    "settings = {\n",
    "    'wandb_project': \"pendulum-ax-test-and-things\",\n",
    "    'model_name': \"ppo-pendulum\",\n",
    "    'ax_experiment_name': \"ppo-pendulum-experiment\",\n",
    "    'ax_objective_name': \"avg_ep_rew\",\n",
    "    'replay_buffer_name': None,\n",
    "    'save_dir': \"checkpoints\",\n",
    "    'checkpoint_freq': 10_000,\n",
    "    'steps_per_test': 100,\n",
    "    'tests_per_check': 10,\n",
    "    'total_steps': 100_000,\n",
    "    'num_trials': 30,\n",
    "    'seed': 42,\n",
    "    'verbose_ax': False,\n",
    "    'verbose_wandb': False,\n",
    "    'verbose_train': 0,\n",
    "    'verbose_log': 0,\n",
    "    'verbose_test': 0,\n",
    "    'verbose_trial': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9381d59b-cfd5-4e9c-bcea-d518ff634da8",
   "metadata": {
    "id": "9381d59b-cfd5-4e9c-bcea-d518ff634da8"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters we want to optimize\n",
    "# Ref: https://github.com/facebook/Ax/blob/6443cee30cbf8cec290200a7420a3db08e4b5445/ax/service/ax_client.py#L236\n",
    "# Example: https://github.com/facebook/Ax/blob/main/tutorials/tune_cnn_service.ipynb\n",
    "# Hyperparameters: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#stable_baselines3.ppo.PPO\n",
    "hparams = [\n",
    "    {\n",
    "        'name': \"n_envs\",\n",
    "        'type': \"fixed\",\n",
    "        'value_type': \"int\",\n",
    "        'value': 1,\n",
    "    },\n",
    "    {\n",
    "        'name': \"learning_rate\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [1e-5, 1e-2],\n",
    "        'log_scale': True,\n",
    "    },\n",
    "    {\n",
    "        'name': \"steps_per_update_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [6, 12], # Inclusive, 2**n between [64, 4096]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"batch_size_div_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [0, 3], # Inclusive, 2**n between [1, 8]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"gamma\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"float\",\n",
    "        'bounds': [0.9, 0.99],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"entropy_coef\",\n",
    "        'value_type': \"float\",\n",
    "        'type': \"range\",\n",
    "        'bounds': [0.0, 0.1],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"use_sde\",\n",
    "        'value_type': \"bool\",\n",
    "        'type': \"choice\",\n",
    "        'values': [True, False],\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"sde_freq\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [-1, 8],\n",
    "        'log_scale': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_1_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [5, 8], # Inclusive, 2**n between [32, 256]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "    {\n",
    "        'name': \"layer_2_pow2\",\n",
    "        'type': \"range\",\n",
    "        'value_type': \"int\",\n",
    "        'bounds': [5, 8], # Inclusive, 2**n between [32, 256]\n",
    "        'log_scale': False,\n",
    "        'is_ordered': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Set parameter constraints\n",
    "# Example: https://github.com/facebook/Ax/issues/621\n",
    "parameter_constraints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b899e21-fb75-40fd-a993-20daca29f37c",
   "metadata": {
    "id": "4b899e21-fb75-40fd-a993-20daca29f37c"
   },
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except NameError:\n",
    "    pass\n",
    "env = gym.make('Pendulum-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0deb7947-5b65-4ea2-a76f-f43eeb44438c",
   "metadata": {
    "id": "0deb7947-5b65-4ea2-a76f-f43eeb44438c"
   },
   "outputs": [],
   "source": [
    "# Cosntruct path to Ax experiment snapshot file\n",
    "ax_snapshot_path = os.path.join(settings['save_dir'], f\"{settings['ax_experiment_name']}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38fa574f-6ca8-4f17-973e-ec5d357b73de",
   "metadata": {
    "id": "38fa574f-6ca8-4f17-973e-ec5d357b73de"
   },
   "outputs": [],
   "source": [
    "# DANGER! Uncomment to delete the experiment file to start over\n",
    "# os.remove(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7661e759-287b-412b-a371-c5dd0f7f8323",
   "metadata": {
    "id": "7661e759-287b-412b-a371-c5dd0f7f8323"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 10-11 20:16:46] ax.service.ax_client: Random seed set to 42. Note that this setting only affects the Sobol quasi-random generator and BoTorch-powered Bayesian optimization models. For the latter models, setting random seed to the same number for two optimizations will make the generated trials similar, but not exactly the same, and over time the trials will diverge more.\n",
      "C:\\Users\\sgmustadio\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\ax\\core\\parameter.py:517: UserWarning:\n",
      "\n",
      "`sort_values` is not specified for `ChoiceParameter` \"use_sde\". Defaulting to `True` for parameters of `ParameterType` BOOL. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "\n",
      "[INFO 10-11 20:16:46] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[FixedParameter(name='n_envs', parameter_type=INT, value=1), RangeParameter(name='learning_rate', parameter_type=FLOAT, range=[1e-05, 0.01], log_scale=True), RangeParameter(name='steps_per_update_pow2', parameter_type=INT, range=[6, 12]), RangeParameter(name='batch_size_div_pow2', parameter_type=INT, range=[0, 3]), RangeParameter(name='gamma', parameter_type=FLOAT, range=[0.9, 0.99]), RangeParameter(name='entropy_coef', parameter_type=FLOAT, range=[0.0, 0.1]), ChoiceParameter(name='use_sde', parameter_type=BOOL, values=[False, True], is_ordered=False, sort_values=True), RangeParameter(name='sde_freq', parameter_type=INT, range=[-1, 8]), RangeParameter(name='layer_1_pow2', parameter_type=INT, range=[5, 8]), RangeParameter(name='layer_2_pow2', parameter_type=INT, range=[5, 8])], parameter_constraints=[]).\n",
      "[INFO 10-11 20:16:46] ax.modelbridge.dispatch_utils: Using Models.GPEI since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 10-11 20:16:46] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=9 num_trials=None use_batch_trials=False\n",
      "[INFO 10-11 20:16:46] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=18\n",
      "[INFO 10-11 20:16:46] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=18\n",
      "[INFO 10-11 20:16:46] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 18 trials, GPEI for subsequent trials]). Iterations after 18 will take longer to generate due to model-fitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new experiment. Snapshot to be saved at checkpoints\\ppo-pendulum-experiment.json.\n"
     ]
    }
   ],
   "source": [
    "# Load experiment from snapshot if it exists, otherwise create a new one\n",
    "# Ref: https://ax.dev/versions/0.2.10/api/service.html#ax.service.ax_client.AxClient.create_experiment\n",
    "if os.path.exists(ax_snapshot_path):\n",
    "    print(f\"Loading experiment from snapshot: {ax_snapshot_path}\")\n",
    "    ax_client = AxClient.load_from_json_file(ax_snapshot_path)\n",
    "else:\n",
    "    print(f\"Creating new experiment. Snapshot to be saved at {ax_snapshot_path}.\")\n",
    "    ax_client = AxClient(\n",
    "        random_seed=settings['seed'],\n",
    "        verbose_logging=settings['verbose_ax'],\n",
    "    )\n",
    "    ax_client.create_experiment(\n",
    "        name=settings['ax_experiment_name'],\n",
    "        parameters=hparams,\n",
    "        objective_name=settings['ax_objective_name'],\n",
    "        minimize=False,\n",
    "        parameter_constraints=parameter_constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "122edfe0-6999-46fb-97ad-c91c280250eb",
   "metadata": {
    "id": "122edfe0-6999-46fb-97ad-c91c280250eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial 0 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run ID: q219vpnp\n",
      "WandB run name: 2023-10-12 02:16:48\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (8, 1)) of distribution Normal(loc: torch.Size([8, 1]), scale: torch.Size([8, 1])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan]], device='cuda:0', grad_fn=<AddmmBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform trial\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m avg_ep_rew \u001b[38;5;241m=\u001b[39m \u001b[43mdo_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_hparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(\n\u001b[0;32m     16\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39mtrial_index,\n\u001b[0;32m     17\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39mavg_ep_rew,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save experiment snapshot\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 82\u001b[0m, in \u001b[0;36mdo_trial\u001b[1;34m(settings, hparams)\u001b[0m\n\u001b[0;32m     70\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m EvalAndSaveCallback(\n\u001b[0;32m     71\u001b[0m     check_freq\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_freq\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     72\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     verbose\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Choo choo train\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_to_complete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Get dataframe of run metrics\u001b[39;00m\n\u001b[0;32m     86\u001b[0m history \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mApi()\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhistory()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:281\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:210\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mreset_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m--> 210\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\policies.py:699\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    697\u001b[0m     latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(pi_features)\n\u001b[0;32m    698\u001b[0m     latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_critic(vf_features)\n\u001b[1;32m--> 699\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n\u001b[0;32m    701\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\policies.py:656\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    653\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\stable_baselines3\\common\\distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\distributions\\normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\distributions\\distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m             )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (8, 1)) of distribution Normal(loc: torch.Size([8, 1]), scale: torch.Size([8, 1])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan],\n        [nan]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     ]
    }
   ],
   "source": [
    "# Choo choo! Perform trials to optimize hyperparameters\n",
    "while True:\n",
    "\n",
    "    # Get next hyperparameters and end experiment if we've reached max trials\n",
    "    next_hparams, trial_index = ax_client.get_next_trial()\n",
    "    if trial_index >= settings['num_trials']:\n",
    "        break\n",
    "\n",
    "    # Show that we're starting a new trial\n",
    "    if settings['verbose_trial'] > 0:\n",
    "        print(f\"--- Trial {trial_index} ---\")\n",
    "\n",
    "    # Perform trial\n",
    "    avg_ep_rew = do_trial(settings, next_hparams)\n",
    "    ax_client.complete_trial(\n",
    "        trial_index=trial_index,\n",
    "        raw_data=avg_ep_rew,\n",
    "    )\n",
    "\n",
    "    # Save experiment snapshot\n",
    "    ax_client.save_to_json_file(ax_snapshot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bq9bZrWWRuOF",
   "metadata": {
    "id": "Bq9bZrWWRuOF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aad847-19f7-4109-8f4a-ca98b07c50b5",
   "metadata": {
    "id": "66aad847-19f7-4109-8f4a-ca98b07c50b5"
   },
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5b7fd-83d9-4842-9b6d-039048f777b3",
   "metadata": {
    "id": "acd5b7fd-83d9-4842-9b6d-039048f777b3"
   },
   "outputs": [],
   "source": [
    "# Create a dummy run so we can programmatically obtain the W&B username\n",
    "wandb_api = wandb.Api()\n",
    "dummy_run = wandb.init()\n",
    "wandb_entity = wandb.run.entity\n",
    "dummy_id = dummy_run.id\n",
    "dummy_run.finish()\n",
    "# wandb_run = wandb_api.run(f\"{wandb_entity}/{settings['wandb_project']}/{dummy_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149866e-653d-4547-8f09-4604399850f9",
   "metadata": {
    "id": "f149866e-653d-4547-8f09-4604399850f9"
   },
   "outputs": [],
   "source": [
    "# Create a list of average test reward for each trial\n",
    "runs = wandb_api.runs(path=f\"{wandb_entity}/{settings['wandb_project']}\")\n",
    "trial_rews = []\n",
    "for r in reversed(runs):\n",
    "    trial_rew = r.summary.get('Average test episode reward')\n",
    "    if trial_rew is not None:\n",
    "        trial_rews.append(trial_rew)\n",
    "\n",
    "# Plot the list of test rewards over time\n",
    "plt.plot(trial_rews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f4e7b-81d2-446b-b35a-9b80f9f5749b",
   "metadata": {
    "id": "c95f4e7b-81d2-446b-b35a-9b80f9f5749b"
   },
   "source": [
    "## Train agent with best hyperparameters\n",
    "\n",
    "Note that you may need to manually adjust some of the hyperparameters to make everything work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe2576-b354-4a29-af68-7ce5bc78b3b0",
   "metadata": {
    "id": "5fbe2576-b354-4a29-af68-7ce5bc78b3b0"
   },
   "outputs": [],
   "source": [
    "# Get from W&B dashboard\n",
    "hparams = {\n",
    "    'n_envs': 1,\n",
    "    'learning_rate': 0.0078,\n",
    "    'steps_per_update_pow2': 10,\n",
    "    'batch_size_div_pow2': 2,\n",
    "    'gamma': 0.974,\n",
    "    'entropy_coef': 0.0356,\n",
    "    'use_sde': True,\n",
    "    'sde_freq': 4,\n",
    "    'layer_1_pow2': 5,\n",
    "    'layer_2_pow2': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb486e-b0fe-459e-abe2-ccde3bb77133",
   "metadata": {
    "id": "54fb486e-b0fe-459e-abe2-ccde3bb77133"
   },
   "outputs": [],
   "source": [
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except NameError:\n",
    "    pass\n",
    "env = gym.make('Pendulum-v1', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba77d0-89ea-409e-82f7-738cc491c438",
   "metadata": {
    "id": "52ba77d0-89ea-409e-82f7-738cc491c438"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "_ = do_trial(settings, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5eb17-f79a-46ea-90b7-080f758c4b92",
   "metadata": {
    "id": "cdc5eb17-f79a-46ea-90b7-080f758c4b92"
   },
   "source": [
    "## Test fully trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045e5ca-843b-4027-b312-53981020c929",
   "metadata": {
    "id": "5045e5ca-843b-4027-b312-53981020c929"
   },
   "outputs": [],
   "source": [
    "# Model and video settings\n",
    "MODEL_FILENAME = \"checkpoints/ppo-pendulum_70000.zip\"\n",
    "VIDEO_FILENAME = \"2-testing.mp4\"\n",
    "\n",
    "# Create our environment\n",
    "try:\n",
    "    env.close()\n",
    "except NameError:\n",
    "    pass\n",
    "env = gym.make('Pendulum-v1', render_mode='rgb_array')\n",
    "\n",
    "# Load the model\n",
    "model = sb3.PPO.load(MODEL_FILENAME)\n",
    "\n",
    "# Create recorder\n",
    "video = cv2.VideoWriter(VIDEO_FILENAME, FOURCC, FPS, (width, height))\n",
    "\n",
    "# Test the model\n",
    "ep_len, ep_rew, avg_step_time = test_agent(env, model, max_steps=200, video=video, msg=f\"{MODEL_FILENAME}\")\n",
    "print(f\"Episode length: {ep_len}, reward: {ep_rew}, avg step time: {avg_step_time}\")\n",
    "\n",
    "# Close the video writer\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
